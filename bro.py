"""
===========================================================
ðŸ“˜ AddictiveCare / IntelliHeal
AI-ML Based Addiction Recovery & Evaluation System

Author: Sai Suprith
Purpose:
â€¢ Healthcare-grade ML evaluation
â€¢ Academic final year project
â€¢ Live demo ready

This file implements:
â€¢ Core ML models (classification, clustering)
â€¢ NLP (sentiment analysis)
â€¢ Time-series forecasting
â€¢ Dataset upload + evaluation
â€¢ Advanced visualizations (Chart.js)
===========================================================
"""

# =========================
# FLASK CORE
# =========================
from flask import Flask, request, jsonify, render_template_string
from flask_cors import CORS

# =========================
# DATA & UTILITIES
# =========================
import numpy as np
import pandas as pd
import json

# =========================
# MACHINE LEARNING MODELS
# =========================
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# =========================
# MODEL EVALUATION
# =========================
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    roc_auc_score,
    confusion_matrix
)
from sklearn.model_selection import (
    train_test_split,
    StratifiedKFold,
    cross_val_score
)

# =========================
# NLP & TIME SERIES
# =========================
from textblob import TextBlob
from statsmodels.tsa.arima.model import ARIMA

# =========================
# APP INITIALIZATION
# =========================
app = Flask(__name__)
CORS(app)

# =========================================================
# ðŸ”¹ HEALTH CHECK ENDPOINT
# =========================================================
@app.route("/")
def home():
    """
    Used to verify backend availability.
    """
    return jsonify({
        "status": "running",
        "message": "AddictiveCare / IntelliHeal ML backend is live ðŸš€"
    })

# =========================================================
# ðŸ”¹ HTML TEMPLATE (DYNAMIC DASHBOARD)
# =========================================================
UPLOAD_HTML = """
<!DOCTYPE html>
<html>
<head>
<title>AddictiveCare â€“ ML Evaluation Dashboard</title>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

<style>
body {
    font-family: "Segoe UI", Arial;
    background: #f0f2f5;
    padding: 40px;
}
.container {
    max-width: 1200px;
    margin: auto;
}
.card {
    background: white;
    padding: 25px;
    border-radius: 14px;
    margin-bottom: 30px;
    box-shadow: 0 8px 20px rgba(0,0,0,0.08);
}
.metrics {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
    gap: 15px;
}
.metric {
    background: #ecf0f1;
    padding: 15px;
    border-radius: 10px;
    text-align: center;
}
.chart-row {
    display: flex;
    gap: 40px;
    justify-content: center;
    flex-wrap: wrap;
}
canvas {
    max-width: 420px;
}
button {
    background: #3498db;
    color: white;
    border: none;
    padding: 12px 26px;
    border-radius: 8px;
    font-size: 16px;
    cursor: pointer;
}
</style>
</head>

<body>
<div class="container">

<div class="card">
<h2>ðŸ“‚ Upload Real Dataset (CSV)</h2>
<p><b>Rule:</b> Last column must be relapse label (0 / 1)</p>
<form method="post" enctype="multipart/form-data">
<input type="file" name="file" required><br><br>
<button type="submit">Upload & Evaluate</button>
</form>
</div>

{% if metrics %}
<div class="card">
<h2>ðŸ“Š Evaluation Metrics</h2>
<div class="metrics">
{% for k,v in metrics.items() %}
<div class="metric"><b>{{k}}</b><br>{{v}}</div>
{% endfor %}
</div>
</div>

<div class="card">
<h2>ðŸ“ˆ Visualizations</h2>
<div class="chart-row">
<canvas id="barChart"></canvas>
<canvas id="pieChart"></canvas>
</div>
<div class="chart-row">
<canvas id="featureChart"></canvas>
<canvas id="cmChart"></canvas>
</div>
</div>

<script>
document.addEventListener("DOMContentLoaded", function () {

    const metricValues = {{ metrics_list | safe }};
    const metricLabels = {{ metric_labels | safe }};

    // ðŸ”¹ Bar Chart â€“ Metric Comparison
    new Chart(document.getElementById("barChart"), {
        type: "bar",
        data: {
            labels: metricLabels,
            datasets: [{
                label: "Model Metrics",
                data: metricValues,
                backgroundColor: "#3498db"
            }]
        }
    });

    // ðŸ”¹ Pie Chart â€“ Metric Distribution
    new Chart(document.getElementById("pieChart"), {
        type: "pie",
        data: {
            labels: metricLabels,
            datasets: [{
                data: metricValues
            }]
        }
    });

    // ðŸ”¹ Doughnut Chart â€“ Feature Importance
    new Chart(document.getElementById("featureChart"), {
        type: "doughnut",
        data: {
            labels: {{ feature_labels | safe }},
            datasets: [{
                data: {{ feature_importance | safe }}
            }]
        }
    });

    // ðŸ”¹ Confusion Matrix Visualization
    new Chart(document.getElementById("cmChart"), {
        type: "bar",
        data: {
            labels: ["True Negative","False Positive","False Negative","True Positive"],
            datasets: [{
                label: "Confusion Matrix",
                data: {{ confusion | safe }},
                backgroundColor: ["#2ecc71","#e74c3c","#f1c40f","#3498db"]
            }]
        }
    });
});
</script>
{% endif %}

</div>
</body>
</html>
"""

# =========================================================
# ðŸ”¹ DATASET UPLOAD & EVALUATION
# =========================================================
@app.route("/upload", methods=["GET","POST"])
def upload():
    """
    Upload real-world dataset and evaluate using:
    â€¢ Gradient Boosting Classifier
    â€¢ Train-test split
    â€¢ Stratified K-Fold cross-validation
    """

    if request.method == "GET":
        return render_template_string(UPLOAD_HTML)

    # Load dataset
    df = pd.read_csv(request.files["file"])

    # Auto-detect features & label
    X = df.iloc[:, :-1].apply(pd.to_numeric, errors="coerce").fillna(0)
    y = pd.to_numeric(df.iloc[:, -1], errors="coerce").fillna(0)

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        stratify=y,
        random_state=42
    )

    # ðŸ”¹ Primary Model: Gradient Boosting
    model = GradientBoostingClassifier(
        n_estimators=300,
        learning_rate=0.05,
        random_state=42
    )
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:,1]

    # Confusion matrix (TN, FP, FN, TP)
    cm = confusion_matrix(y_test, y_pred).ravel().tolist()

    # Evaluation metrics
    metrics = {
        "Accuracy": round(accuracy_score(y_test, y_pred), 2),
        "F1 Score": round(f1_score(y_test, y_pred), 2),
        "ROC-AUC": round(roc_auc_score(y_test, y_prob), 2),
        "CV Accuracy": round(
            cross_val_score(
                model, X, y,
                cv=StratifiedKFold(5, shuffle=True, random_state=42),
                scoring="accuracy"
            ).mean(), 2
        ),
        "CV F1": round(
            cross_val_score(
                model, X, y,
                cv=StratifiedKFold(5, shuffle=True, random_state=42),
                scoring="f1"
            ).mean(), 2
        )
    }

    return render_template_string(
        UPLOAD_HTML,
        metrics=metrics,
        metrics_list=json.dumps(list(metrics.values())),
        metric_labels=json.dumps(list(metrics.keys())),
        feature_importance=json.dumps(model.feature_importances_.tolist()),
        feature_labels=json.dumps([f"Feature {i+1}" for i in range(X.shape[1])]),
        confusion=json.dumps(cm)
    )

# =========================================================
# ðŸ”¹ APP ENTRY POINT
# =========================================================
if __name__ == "__main__":
    app.run(debug=False)
